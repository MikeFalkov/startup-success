{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, classification_report,\n",
    "    confusion_matrix, average_precision_score\n",
    ")\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n"
   ],
   "id": "b70d945bd5552eec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bc97280ec28edce5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2. Paths\n",
    "RAW_DATA_PATH = Path(\"big_startup_secsees_dataset.csv\")\n",
    "CLEANED_DATA_PATH = Path(\"final/preprocessed_data.csv\")\n"
   ],
   "id": "3c0896ee2f9e2e66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3. Load and Clean Raw Data\n",
    "df = pd.read_csv(RAW_DATA_PATH)\n",
    "\n",
    "df['success'] = df['status'].apply(lambda x: 0 if x == 'closed' else 1)\n",
    "df.drop(columns=['permalink', 'homepage_url', 'name', 'status', 'state_code'], inplace=True)\n",
    "\n",
    "fill_cols = ['category_list', 'country_code', 'region', 'city']\n",
    "df[fill_cols] = df[fill_cols].fillna('Unknown')\n",
    "df.dropna(subset=['first_funding_at'], inplace=True)\n",
    "\n",
    "df['funding_total_usd'] = df['funding_total_usd'].replace('-', np.nan)\n",
    "df['funding_total_usd'] = pd.to_numeric(df['funding_total_usd'], errors='coerce')\n",
    "\n",
    "for col in ['founded_at', 'first_funding_at', 'last_funding_at']:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "df['founded_year'] = df['founded_at'].dt.year\n",
    "df['first_funding_year'] = df['first_funding_at'].dt.year\n",
    "df['last_funding_year'] = df['last_funding_at'].dt.year\n",
    "df['days_to_first_funding'] = (df['first_funding_at'] - df['founded_at']).dt.days\n",
    "df['funding_duration'] = (df['last_funding_at'] - df['first_funding_at']).dt.days\n",
    "\n",
    "df = df[df['funding_total_usd'] <= 5_000_000_000]\n",
    "df = df[(df['founded_year'] >= 1990) & (df['founded_year'] <= 2015)]\n",
    "df.dropna(subset=['days_to_first_funding', 'funding_duration'], inplace=True)\n"
   ],
   "id": "5eddf5e92e60492f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4. Category Clustering via TF-IDF + KMeans\n",
    "unique_categories = pd.Series(df['category_list'].dropna().unique())\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.95, min_df=2)\n",
    "category_matrix = vectorizer.fit_transform(unique_categories)\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "category_clusters = kmeans.fit_predict(category_matrix)\n",
    "category_cluster_map = dict(zip(unique_categories, category_clusters))\n",
    "df['category_cluster'] = df['category_list'].map(category_cluster_map)\n",
    "\n",
    "df.drop(columns=['category_list', 'founded_at', 'first_funding_at', 'last_funding_at'], inplace=True)\n",
    "df.to_csv(CLEANED_DATA_PATH, index=False)\n"
   ],
   "id": "4da539c4f526b372"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 5. Load and Prepare Data for Modeling\n",
    "df = pd.read_csv(CLEANED_DATA_PATH)\n",
    "df.drop(columns=[\"city\"], inplace=True)\n",
    "\n",
    "X = df.drop(columns=[\"success\"])\n",
    "y = df[\"success\"]\n",
    "\n",
    "categorical_features = [\"country_code\", \"region\"]\n",
    "numerical_features = [\n",
    "    \"funding_total_usd\", \"funding_rounds\", \"founded_year\",\n",
    "    \"first_funding_year\", \"last_funding_year\",\n",
    "    \"days_to_first_funding\", \"funding_duration\"\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numerical_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "pipeline = Pipeline([(\"preprocessor\", preprocessor)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train_scaled = pipeline.fit_transform(X_train)\n",
    "X_test_scaled = pipeline.transform(X_test)\n"
   ],
   "id": "3d13389f4728df24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 6. Resample with SMOTE + Tomek\n",
    "sampler = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Resampled training shape: {X_train_resampled.shape}, {y_train_resampled.shape}\")\n"
   ],
   "id": "977a3725171e3926"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 7. Train Balanced Random Forest Model\n",
    "brf_model = BalancedRandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    n_jobs=-1\n",
    ")\n",
    "brf_model.fit(X_train_resampled, y_train_resampled)\n"
   ],
   "id": "b756fc2e2440a913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 8. Threshold Optimization\n",
    "y_proba = brf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "f1_scores_class0 = [\n",
    "    classification_report(y_test, (y_proba >= t).astype(int),\n",
    "                          output_dict=True, zero_division=0)['0']['f1-score']\n",
    "    for t in thresholds\n",
    "]\n",
    "\n",
    "best_index = np.argmax(f1_scores_class0)\n",
    "optimal_threshold = thresholds[best_index]\n",
    "best_f1_score = f1_scores_class0[best_index]\n",
    "y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n"
   ],
   "id": "e47c9bc66ffe632d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 9. Final Evaluation\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_optimal)\n",
    "clf_report = classification_report(y_test, y_pred_optimal, target_names=[\"Failure\", \"Success\"], zero_division=0)\n",
    "\n",
    "print(\"\\n=== Model Performance Summary ===\")\n",
    "print(f\"Optimized Threshold:         {optimal_threshold:.4f}\")\n",
    "print(f\"Class 0 Best F1-Score:       {best_f1_score:.4f}\")\n",
    "print(f\"Precision-Recall AUC:        {pr_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", clf_report)\n"
   ],
   "id": "66b9ed57017a37e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
